{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done here\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dnd.ml_model1 import *\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "print(\"Done here\")\n",
    "4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOte - it could be worth taking initiative handling into a separate function - it's a simpler function?\n",
    "But there may be interplay, so maybe not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = BattleDataGeneration()\n",
    "cols_x, cols_y = gen.get_headings()\n",
    "res =  gen.run_battle_data_1(10)\n",
    "#the run_battle_data_1 is yielding x values and y values,and I need to decouple them...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data returns the scaled x data and y data for 100000 simulated combats\n",
    "x_train, y_train, scaler = get_data(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to get a pair of characters\n",
    "from dnd.util import *\n",
    "from dnd.combat import *\n",
    "\n",
    "def gettestchars():\n",
    "        ch1 = HumanCharacter(gen_character(), \"dwarvish\")\n",
    "        sword1 = MediumLongsword35()\n",
    "        ch1.add_weapon_to_inventory(sword1)\n",
    "        ch2 = HalfOrcCharacter(gen_character())\n",
    "        sword2 = MediumLongsword35()\n",
    "        ch2.add_weapon_to_inventory(sword2)\n",
    "        return ch1,ch2\n",
    "\n",
    "def test_a_model(amodel, scaler):\n",
    "    \n",
    "    ch1,ch2 = gettestchars()\n",
    "    results = get_win_probability_from_simulation(ch1, ch2,1000)\n",
    "    print(\"get_win_probability_from_simulation\", results)\n",
    "\n",
    "    mytest=get_datum(ch1, ch2, scaler)\n",
    "    mytestopposite=get_datum(ch2, ch1, scaler)\n",
    "\n",
    "    pred1 = amodel.predict(mytest)\n",
    "    pred2 = amodel.predict(mytestopposite)\n",
    "    res=(pred1, pred2 )\n",
    "    #Something wrong with model- it is generating a higher than 1.0 prob\n",
    "    \n",
    "    print(\"unnormalized model results\", res)\n",
    "\n",
    "    #res_norm = (res[0]/sum(res), res[1]/sum(res))\n",
    "\n",
    "    #print(\"normalized model results\", res_norm)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.855\n",
      "1    0.145\n",
      "dtype: float64\n",
      "0    0.16\n",
      "1    0.84\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0 sim 1\n",
      "1.0 0.0 sim opposite\n",
      "0.99432546 0.011380941 1.0057064 model1 and opposite\n",
      "0.9951904 0.004809602 1.0 pred model2\n",
      "0.9930143 0.006985728 1.0 pred model2 opposite\n"
     ]
    }
   ],
   "source": [
    "ch1, ch2 = gettestchars()\n",
    "results = get_win_probability_from_simulation(ch1, ch2, 1000)\n",
    "results2 = get_win_probability_from_simulation(ch2, ch1, 1000)\n",
    "d1 = get_datum(ch1, ch2, scaler)\n",
    "d2 = get_datum(ch2, ch1, scaler)\n",
    "pred1 = model1.predict(d1)\n",
    "pred2 = model1.predict(d2)\n",
    "pred21 = model2.predict(d1)\n",
    "pred22 = model2.predict(d2)\n",
    "print(results[0], results[1], \"sim 1\")\n",
    "print(results2[1], results2[0], \"sim opposite\") \n",
    "\n",
    "print(pred1[0][0], pred2[0][0], pred1[0][0] + pred2[0][0], \"model1 and opposite\")\n",
    "print(pred21[0][0],pred21[0][1], pred21[0][0] + pred21[0][1], \"pred model2\")\n",
    "print(pred22[0][1], pred22[0][0], pred22[0][1] + pred22[0][0], \"pred model2 opposite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************\n",
      "Strength: 16\n",
      "Dexterity: 12\n",
      "Constitution: 19\n",
      "Intelligence: 10\n",
      "Wisdom: 15\n",
      "Charisma: 14\n",
      "Effective hit points: 44\n",
      "\n",
      "****************************\n",
      "Strength: 7\n",
      "Dexterity: 8\n",
      "Constitution: 15\n",
      "Intelligence: 14\n",
      "Wisdom: 14\n",
      "Charisma: 15\n",
      "Effective hit points: 42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ch1)\n",
    "print(ch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_win_probability_from_simulation(ch1, ch2, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.99997\n",
      "1    0.00003\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855 0.145 sim 1\n",
      "0.84 0.16 sim opposite\n",
      "0.8627044 0.13121939 model1 and opposite\n",
      "0.89151096 0.10848911 pred model2\n",
      "0.85399324 0.14600682 pred model2 opposite\n"
     ]
    }
   ],
   "source": [
    "print(results[0], results[1], \"sim 1\")\n",
    "print(results2[1], results2[0], \"sim opposite\") \n",
    "\n",
    "print(pred1[0][0], pred2[0][0], \"model1 and opposite\")\n",
    "print(pred21[0][0],pred21[0][1], \"pred model2\")\n",
    "print(pred22[0][1], pred22[0][0], \"pred model2 opposite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7a4ba6f68132>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char1_won</th>\n",
       "      <th>char1_hp_left</th>\n",
       "      <th>char2_won</th>\n",
       "      <th>char2_hp_left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char1_won  char1_hp_left  char2_won  char2_hp_left\n",
       "0       True             14      False              0\n",
       "1       True              1      False              0\n",
       "2      False              0       True              6\n",
       "3      False              0       True             26\n",
       "4      False              0       True             47"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.3964 - accuracy: 0.8308\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 3s 802us/step - loss: 0.3525 - accuracy: 0.8415\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 3s 807us/step - loss: 0.3465 - accuracy: 0.8432\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 3s 803us/step - loss: 0.3430 - accuracy: 0.8441\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 2s 792us/step - loss: 0.3401 - accuracy: 0.8451\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 3s 810us/step - loss: 0.3382 - accuracy: 0.8458\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 3s 822us/step - loss: 0.3369 - accuracy: 0.84630s - loss: 0.3366 - accuracy:  - ETA: 0s - loss: 0.3368 - accuracy:  - ETA: 0s - loss: 0.3367 - accuracy: 0.84\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 2s 789us/step - loss: 0.3362 - accuracy: 0.84621s - loss: 0.3378 - accu - ETA: 1s - loss: - ETA: 0s - loss: 0.3364 -  - ETA: 0s - loss: 0.3360 - accu\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 3s 936us/step - loss: 0.3357 - accuracy: 0.8456\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.3353 - accuracy: 0.8456: 0s - loss: 0.335\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "test_a_model() missing 1 required positional argument: 'scaler'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ccac16716895>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_training_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"char1_won\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_training_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtest_a_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: test_a_model() missing 1 required positional argument: 'scaler'"
     ]
    }
   ],
   "source": [
    "model1=build_model_1()\n",
    "y_training_values = y_train[[\"char1_won\"]].to_numpy().astype(float)\n",
    "model1.fit(x_train, y_training_values, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_win_probability_from_simulation 0    0.242\n",
      "1    0.758\n",
      "dtype: float64\n",
      "unnormalized model results (array([[0.31020218]], dtype=float32), array([[0.68521714]], dtype=float32))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.31020218]], dtype=float32), array([[0.68521714]], dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_a_model(model1, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_win_probability_from_simulation 0    0.92\n",
      "1    0.08\n",
      "dtype: float64\n",
      "unnormalized model results (array([[0.94630986]], dtype=float32), array([[0.0544098]], dtype=float32))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.94630986]], dtype=float32), array([[0.0544098]], dtype=float32))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_a_model(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 3s 917us/step - loss: 0.4140 - accuracy: 0.8196\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 3s 881us/step - loss: 0.3510 - accuracy: 0.8421\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 3s 986us/step - loss: 0.3431 - accuracy: 0.8444\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 3s 873us/step - loss: 0.3394 - accuracy: 0.8443\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 3s 870us/step - loss: 0.3374 - accuracy: 0.8457\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 3s 929us/step - loss: 0.3363 - accuracy: 0.8459\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 3s 851us/step - loss: 0.3359 - accuracy: 0.8459\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 3s 894us/step - loss: 0.3354 - accuracy: 0.8459\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 3s 923us/step - loss: 0.3353 - accuracy: 0.8461\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 3s 995us/step - loss: 0.3349 - accuracy: 0.84650s - loss: 0.3351 - \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29b20b6e448>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model2=build_model_2()\n",
    "y_training_values = y_train[[\"char1_won\", \"char2_won\"]].to_numpy().astype(float)\n",
    "model2.fit(x_train, y_training_values, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_win_probability_from_simulation 0    0.43\n",
      "1    0.57\n",
      "dtype: float64\n",
      "unnormalized model results (array([[0.48018116, 0.5198188 ]], dtype=float32), array([[0.43092483, 0.5690752 ]], dtype=float32))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.48018116, 0.5198188 ]], dtype=float32),\n",
       " array([[0.43092483, 0.5690752 ]], dtype=float32))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_a_model(model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_win_probability_from_simulation 0    0.619\n",
      "1    0.381\n",
      "dtype: float64\n",
      "unnormalized model results (array([[0.8022876]], dtype=float32), array([[0.31684875]], dtype=float32))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.8022876]], dtype=float32), array([[0.31684875]], dtype=float32))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_a_model(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_single_random_fight_and_compare_percentage_chance_vs_neural_net(model2, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00000007"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding an extra column to the y_train - will need to get it added throughout...and\n",
    "#need a softmax in the model\n",
    "sum([0.33931077, 0.6606893 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_datum should return the X variables for a particular pair of characters so I can use it to predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_datum is used by the function show_single_random_fight_and_compare_percentage_chance_vs_neural_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from simulation 0.2524, then 0.2491\tNeural result: 0.4713372588157654\tDifference: -0.21893725881576537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'simulation': 0.2524, 'model': 0.47133726}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 40)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.predict() is meant for batches, instead need model(x1) - but that didn't work! Not sure what needs to be prepared for model\n",
    "x1 = x_train_scaled.iloc[0:1,:]\n",
    "model.predict(x1)\n",
    "\n",
    "x_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to get a pair of characters\n",
    "from dnd.util import *\n",
    "from dnd.combat import *\n",
    "def test_a_model(amodel, scaler):\n",
    "    ch1 = HumanCharacter(gen_character(), \"dwarvish\")\n",
    "    sword1 = MediumLongsword35()\n",
    "    ch1.add_weapon_to_inventory(sword1)\n",
    "    ch2 = HalfOrcCharacter(gen_character())\n",
    "    sword2 = MediumLongsword35()\n",
    "    ch2.add_weapon_to_inventory(sword2)\n",
    "\n",
    "    results = get_win_probability_from_simulation(ch1, ch2,1000)\n",
    "    print(\"get_win_probability_from_simulation\", results)\n",
    "\n",
    "    mytest=get_datum(ch1, ch2, scaler)\n",
    "    mytestopposite=get_datum(ch2, ch1, scaler)\n",
    "\n",
    "    res=(amodel.predict(mytest), amodel.predict(mytestopposite))\n",
    "    #Something wrong with model- it is generating a higher than 1.0 prob\n",
    "    \n",
    "    print(\"unnormalized model results\", res)\n",
    "    #res_norm = (res[0]/sum(res), res[1]/sum(res))\n",
    "\n",
    "    #print(\"normalized model results\", res_norm)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0    0.271\n",
      "1    0.729\n",
      "dtype: float64, 0    0.735\n",
      "1    0.265\n",
      "dtype: float64)\n",
      "(1.0, 1.0)\n",
      "(0.5, 0.5)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 3s 937us/step - loss: 0.4867 - accuracy: 0.7799\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.3694 - accuracy: 0.8412\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 3s 923us/step - loss: 0.3528 - accuracy: 0.8421\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 3s 899us/step - loss: 0.3469 - accuracy: 0.8430\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 3s 896us/step - loss: 0.3433 - accuracy: 0.84401s - loss: 0.3461 - accuracy:  - ETA: 1s - loss: 0.3459  - ETA: 0s - los\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 3s 864us/step - loss: 0.3412 - accuracy: 0.8447\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 3s 845us/step - loss: 0.3399 - accuracy: 0.8448\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 3s 964us/step - loss: 0.3390 - accuracy: 0.84501s - loss: 0.3390 -  - ETA: 0s - los\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 3s 987us/step - loss: 0.3382 - accuracy: 0.8450\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 3s 995us/step - loss: 0.3379 - accuracy: 0.8452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x173dec9b4c8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled, (y_train[[\"char1_won\"]]).to_numpy(), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-8ba059ac1f54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"char1_won\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, (y_test[[\"char1_won\"]]).to_numpy(), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do I get the values for a particular output, or for an inner portion of the network?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model.evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "### Generate a new pair of characters and simulate combat, then compare the win/loss ratio to the one predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_character' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a3a99f34fa76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-a3a99f34fa76>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mchar1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_character\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mchar2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_character\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generate_character' is not defined"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    char1 = generate_character()\n",
    "    char2 = generate_character()\n",
    "    print(char1, char2)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   greeting  first  second  third\n",
      "0         4      1       2      4\n"
     ]
    }
   ],
   "source": [
    "dta = [4, 1, 2, 4]\n",
    "cols = [\"greeting\", \"first\", \"second\", \"third\"]\n",
    "import pandas as pd\n",
    "res = pd.DataFrame(data=[dta], columns=cols)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Race\n",
      "0    Human\n",
      "1  HalfOrc\n",
      "2    Human\n",
      "   char1_is_human  char1_is_halforc\n",
      "0             1.0               0.0\n",
      "1             0.0               1.0\n",
      "2             1.0               0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "race=OneHotEncoder(categories=[[\"Human\", \"HalfOrc\"]], sparse=False)\n",
    "\n",
    "df = pd.DataFrame(data=[[\"Human\"], [\"HalfOrc\"], [\"Human\"]], columns=[\"Race\"])\n",
    "print(df)\n",
    "prefix=\"char1\"\n",
    "res=pd.DataFrame(race.fit_transform(df), columns=[f\"{prefix}_is_human\", f\"{prefix}_is_halforc\"])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Longsword', 'Warhammer', 'Falchion', 'BastardSword', 'Scimitar']\n"
     ]
    }
   ],
   "source": [
    "weapontypes=[w.weapon_type for w in BattleDataGeneration().weapons] #Yuck\n",
    "print(weapontypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dndsim",
   "language": "python",
   "name": "dndsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
